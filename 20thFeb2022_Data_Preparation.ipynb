{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.21.2-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 22.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Using cached s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.25.0,>=1.24.2\n",
      "  Downloading botocore-1.24.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 68.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.25.0,>=1.24.2->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.25.0,>=1.24.2->boto3) (1.25.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.2->boto3) (1.15.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.18.14\n",
      "    Uninstalling botocore-1.18.14:\n",
      "      Successfully uninstalled botocore-1.18.14\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.3\n",
      "    Uninstalling s3transfer-0.3.3:\n",
      "      Successfully uninstalled s3transfer-0.3.3\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "awscli 1.18.155 requires botocore==1.18.14, but you'll have botocore 1.24.2 which is incompatible.\n",
      "awscli 1.18.155 requires s3transfer<0.4.0,>=0.3.0, but you'll have s3transfer 0.5.1 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.21.2 botocore-1.24.2 s3transfer-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Using cached s3fs-2022.1.0-py3-none-any.whl (25 kB)\n",
      "Processing ./.cache/pip/wheels/c2/3f/42/08dc768873808d05f326167ead3fdc6f1b742a6253bd3ec6a3/aiobotocore-2.1.1-py3-none-any.whl\n",
      "Collecting aiohttp<=4\n",
      "  Using cached aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "Collecting fsspec==2022.01.0\n",
      "  Using cached fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.8/site-packages (from aiobotocore~=2.1.0->s3fs) (1.12.1)\n",
      "Collecting botocore<1.23.25,>=1.23.24\n",
      "  Using cached botocore-1.23.24-py3-none-any.whl (8.4 MB)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Using cached aioitertools-0.9.0-py3-none-any.whl (22 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp<=4->s3fs) (20.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.23.25,>=1.23.24->aiobotocore~=2.1.0->s3fs) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.23.25,>=1.23.24->aiobotocore~=2.1.0->s3fs) (2.8.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.23.25,>=1.23.24->aiobotocore~=2.1.0->s3fs) (0.10.0)\n",
      "Collecting typing_extensions>=4.0; python_version < \"3.10\"\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp<=4->s3fs) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.25,>=1.23.24->aiobotocore~=2.1.0->s3fs) (1.15.0)\n",
      "Installing collected packages: botocore, charset-normalizer, multidict, yarl, async-timeout, frozenlist, aiosignal, aiohttp, typing-extensions, aioitertools, aiobotocore, fsspec, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.2\n",
      "    Uninstalling botocore-1.24.2:\n",
      "      Successfully uninstalled botocore-1.24.2\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.2\n",
      "    Uninstalling typing-extensions-3.7.4.2:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.3\n",
      "    Uninstalling fsspec-0.8.3:\n",
      "      Successfully uninstalled fsspec-0.8.3\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "boto3 1.21.2 requires botocore<1.25.0,>=1.24.2, but you'll have botocore 1.23.24 which is incompatible.\n",
      "awscli 1.18.155 requires botocore==1.18.14, but you'll have botocore 1.23.24 which is incompatible.\n",
      "awscli 1.18.155 requires s3transfer<0.4.0,>=0.3.0, but you'll have s3transfer 0.5.1 which is incompatible.\u001b[0m\n",
      "Successfully installed aiobotocore-2.1.1 aiohttp-3.8.1 aioitertools-0.9.0 aiosignal-1.2.0 async-timeout-4.0.2 botocore-1.23.24 charset-normalizer-2.0.12 frozenlist-1.3.0 fsspec-2022.1.0 multidict-6.0.2 s3fs-2022.1.0 typing-extensions-4.1.1 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing 100K charts and creating the main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rx</th>\n",
       "      <th>rxcui</th>\n",
       "      <th>parent_rxcui</th>\n",
       "      <th>parent_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saw palmetto extract</td>\n",
       "      <td>236344</td>\n",
       "      <td>236344</td>\n",
       "      <td>saw palmetto extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nivestym injectable product</td>\n",
       "      <td>2057204</td>\n",
       "      <td>68442</td>\n",
       "      <td>filgrastim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naprelan oral product</td>\n",
       "      <td>1178761</td>\n",
       "      <td>7258</td>\n",
       "      <td>naproxen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vistaril 25 mg oral capsule</td>\n",
       "      <td>995255</td>\n",
       "      <td>5553</td>\n",
       "      <td>hydroxyzine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>latrodectus mactans antivenin 6000 unt</td>\n",
       "      <td>1867738</td>\n",
       "      <td>89887</td>\n",
       "      <td>Latrodectus mactans antivenin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       rx    rxcui  parent_rxcui  \\\n",
       "0                    saw palmetto extract   236344        236344   \n",
       "1             nivestym injectable product  2057204         68442   \n",
       "2                   naprelan oral product  1178761          7258   \n",
       "3             vistaril 25 mg oral capsule   995255          5553   \n",
       "4  latrodectus mactans antivenin 6000 unt  1867738         89887   \n",
       "\n",
       "                     parent_name  \n",
       "0           saw palmetto extract  \n",
       "1                     filgrastim  \n",
       "2                       naproxen  \n",
       "3                    hydroxyzine  \n",
       "4  Latrodectus mactans antivenin  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading medicine_mapping to create parent_rxcui_mapping\n",
    "medicine_mapping = pd.read_csv(\"medicine_with_name_V1.0.csv\")\n",
    "medicine_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meat_text(meat):\n",
    "    \"\"\"\n",
    "    Function to obtain a list of text for every code1 with meat which has the type as medicine\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meat : entities[\"meat_entities\"]\n",
    "        Series/column of meat_entities for every code1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    text : list\n",
    "        Returns a list of text for every code1 with meat which has type as medicine\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    for i in meat:\n",
    "        if i[\"type\"].lower() == 'medicine':\n",
    "            text.append(i[\"text\"].lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rxcui_mapping(meat_text):\n",
    "    \"\"\"\n",
    "    Function to obtain a list of parent_rxcui_mapping for every code1 with meat which has the type as medicine\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meat_text : entities[\"meat_entities_text\"]\n",
    "        Series/column of meat_entities_text for every code1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parent_rxcui_mapping : list\n",
    "        Returns a list of parent_rxcui_mapping for every code1 with meat which has the type as medicine\n",
    "    \"\"\"\n",
    "    parent_rxcui_mapping = []\n",
    "    for i in meat_text:\n",
    "        if i in medicine_mapping.rx.values:\n",
    "            parent_rxcui_mapping.append(medicine_mapping[medicine_mapping[\"rx\"] == i][\"parent_rxcui\"].values)\n",
    "    return parent_rxcui_mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "bucket_name = 'epicypher'\n",
    "folder_name = 'Experiments/Aishwarya/Autocoding/data/'\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "charts_with_no_enc_id = []\n",
    "charts_with_enc_id = []\n",
    "data_with_enc_id = []\n",
    "data_with_no_enc_id = []\n",
    "\n",
    "number_of_files = 0\n",
    "\n",
    "for obj in bucket.objects.filter(Prefix=folder_name):\n",
    "    if number_of_files == 120000:\n",
    "        break\n",
    "\n",
    "    if number_of_files >= 0:\n",
    "        \n",
    "        print(number_of_files)\n",
    "            \n",
    "        i = str(obj.key).split('Experiments/Aishwarya/Autocoding/data/')[-1]\n",
    "\n",
    "        s3_client = boto3.client('s3')\n",
    "        json_obj = s3_client.get_object(Bucket=bucket_name, Key=obj.key)\n",
    "        json_data = json_obj[\"Body\"].read().decode('utf-8')\n",
    "        data1 = json.loads(json_data)\n",
    "\n",
    "        if 'entities_with_highlights' not in data1.keys():\n",
    "            continue\n",
    "        entities = pd.json_normalize(data1,record_path = ['entities_with_highlights'],meta=['NLP_VERSION'])\n",
    "\n",
    "        if len(entities):\n",
    "\n",
    "            if 'enc_id' not in entities.columns:\n",
    "                charts_with_no_enc_id.append(i)\n",
    "                \n",
    "                entities['meat_entities'] = entities.apply(lambda x: [data1['meat_entities'][i] for i in x['meat']] if x['type']=='Disease' else None, axis=1)\n",
    "\n",
    "                entities['meat_entities_text'] = entities[\"meat_entities\"].map(lambda x: meat_text(x) if x else None)\n",
    "\n",
    "                entities['meat_entities_type'] = entities.apply(lambda x: [data1['meat_entities'][i][\"type\"].lower() for i in x['meat']] if x['type']=='Disease' else None, axis=1)\n",
    "\n",
    "                entities[\"parent_rxcui_mapping\"] = entities[\"meat_entities_text\"].map(lambda x: rxcui_mapping(x) if x else None)\n",
    "\n",
    "                entities[\"final_code_family\"] = entities[\"final_codes\"].apply(lambda x: [i[:3] for i in x] if x else None)\n",
    "                \n",
    "                encounters = pd.json_normalize(data1,record_path = ['encounters'])\n",
    "                \n",
    "                entities[\"enc_id\"] = entities[\"page\"].apply(lambda x: encounters[(encounters['start'] <= x) & (encounters['end'] >= x)][\"enc_id\"].iloc[0])\n",
    "             \n",
    "                final_data = entities.merge(encounters,on ='enc_id')\n",
    "\n",
    "                final_data['chart_id'] = i \n",
    "\n",
    "                data_with_no_enc_id.append(final_data)            \n",
    "            else:\n",
    "                charts_with_enc_id.append(i)\n",
    "\n",
    "                entities['meat_entities'] = entities.apply(lambda x: [data1['meat_entities'][i] for i in x['meat']] if x['type']=='Disease' else None, axis=1)\n",
    "\n",
    "                entities['meat_entities_text'] = entities[\"meat_entities\"].map(lambda x: meat_text(x) if x else None)\n",
    "\n",
    "                entities['meat_entities_type'] = entities.apply(lambda x: [data1['meat_entities'][i][\"type\"].lower() for i in x['meat']] if x['type']=='Disease' else None, axis=1)\n",
    "\n",
    "                entities[\"parent_rxcui_mapping\"] = entities[\"meat_entities_text\"].map(lambda x: rxcui_mapping(x) if x else None)\n",
    "\n",
    "                entities[\"final_code_family\"] = entities[\"final_codes\"].apply(lambda x: [i[:3] for i in x] if x else None)\n",
    "\n",
    "                encounters = pd.json_normalize(data1,record_path = ['encounters'])\n",
    "\n",
    "                final_data = entities.merge(encounters,on ='enc_id')\n",
    "\n",
    "                final_data['chart_id'] = i \n",
    "\n",
    "                data_with_enc_id.append(final_data)\n",
    "        \n",
    "    number_of_files = number_of_files + 1\n",
    "    \n",
    "print(\"Number of charts with no enc_id -->\",len(charts_with_no_enc_id))\n",
    "print(\" \")\n",
    "print(\"Number of charts with enc_id -->\",len(charts_with_enc_id))\n",
    "print(\" \")\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id = pd.concat((x for x in data_with_no_enc_id),ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_enc_id = pd.concat((x for x in data_with_enc_id),ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaing dataset for the model - 100k charts (Training data) and 20k charts (Test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_100k_105k = pd.read_csv(\"data_with_no_enc_id_100k_105k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_100k_105k.drop(columns = ['Unnamed: 0','x1', 'y1', 'x2', 'y2', 'h_page', 'w_page'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only need code1 with type as Disease as the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_100k_105k = data_with_no_enc_id_100k_105k[data_with_no_enc_id_100k_105k[\"type\"] == \"Disease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_105k_110k = pd.read_csv(\"data_with_no_enc_id_105k_110k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_105k_110k.drop(columns = ['Unnamed: 0','x1', 'y1', 'x2', 'y2', 'h_page', 'w_page'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_105k_110k = data_with_no_enc_id_105k_110k[data_with_no_enc_id_105k_110k[\"type\"] == \"Disease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_110k_120k = pd.read_csv(\"data_with_no_enc_id_110k_120k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_110k_120k.drop(columns = ['Unnamed: 0','x1', 'y1', 'x2', 'y2', 'h_page', 'w_page'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_110k_120k = data_with_no_enc_id_110k_120k[data_with_no_enc_id_110k_120k[\"type\"] == \"Disease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_100k_120k_merged = pd.concat([data_with_no_enc_id_100k_105k,data_with_no_enc_id_105k_110k,\n",
    "                                                  data_with_no_enc_id_110k_120k],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437454, 45)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_no_enc_id_100k_120k_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_100k_120k_merged.to_csv(\"16thFeb2022_data_with_no_enc_id_100k_120k_main_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_100k_120k_merged = pd.read_csv(\"16thFeb2022_data_with_no_enc_id_100k_120k_main_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_no_enc_id_100k_120k_merged.drop(columns = ['Unnamed: 0','exact_match', 'additional_codes','checkbox'\n",
    "                                         ,'start_x', 'end_x','start_y', 'end_y','HCC Description',\n",
    "                                         'DX Description', 'DXCAT3DESC'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_enc_id_100k_120k_merged = pd.read_csv(\"16thFeb2022_data_100k_120k_main_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_enc_id_100k_120k_merged.drop(columns = ['Unnamed: 0', 'additional_codes',\n",
    "                                         'start_x', 'end_x','start_y', 'end_y','HCC Description',\n",
    "                                         'DX Description', 'DXCAT3DESC'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_100k_120k_merged = pd.concat([data_with_enc_id_100k_120k_merged,data_with_no_enc_id_100k_120k_merged],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_100k_120k_merged.to_csv(\"16thFeb2022_100k_120k_merged_main_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data to merge with sf data and prepare the output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"16thFeb2022_100k_120k_merged_main_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disease    1805764\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'code1', 'code2', 'combo_add_codes', 'final_codes',\n",
       "       'query_source', 'DX Codetype', 'DX Category', 'DX Condition Type',\n",
       "       'DXCAT3', 'enc_id', 'is_meat', 'meat', 'id_', 'text', 'type', 'page',\n",
       "       'section', 'DX Context', 'NLP_VERSION', 'meat_entities',\n",
       "       'meat_entities_text', 'meat_entities_type', 'parent_rxcui_mapping',\n",
       "       'final_code_family', 'telehealth_encounter', 'dos_start', 'dos_end',\n",
       "       'enc_class', 'unique_codes', 'code_count', 'npi.name', 'npi.location',\n",
       "       'npi.speciality', 'npi.type', 'chart_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0', 'code2','id_','type','npi.name', 'npi.location','npi.speciality','type',\n",
    "                                         'combo_add_codes', 'is_meat'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating features - Count of type of meat for every code1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"medicine_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('medicine') if x != \"[]\" else 0)\n",
    "df[\"labtest_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('labtest') if x != \"[]\" else 0)\n",
    "df[\"embedded radiology/lab results_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('embedded radiology/lab results') if x != \"[]\" else 0)\n",
    "df[\"devices_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('devices') if x != \"[]\" else 0)\n",
    "df[\"abnormal findings_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('abnormal findings') if x != \"[]\" else 0)\n",
    "df[\"generic term_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('generic term') if x != \"[]\" else 0)\n",
    "df[\"plan_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('plan') if x != \"[]\" else 0)\n",
    "df[\"procedure_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('procedure') if x != \"[]\" else 0)\n",
    "df[\"radiology_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('radiology') if x != \"[]\" else 0)\n",
    "df[\"labs_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('labs') if x != \"[]\" else 0)\n",
    "df[\"rx_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('rx') if x != \"[]\" else 0)\n",
    "df[\"referral_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('referral') if x != \"[]\" else 0)\n",
    "df[\"symptoms_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('symptoms') if x != \"[]\" else 0)\n",
    "df[\"therapy_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('therapy') if x != \"[]\" else 0)\n",
    "df[\"procedures_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('procedures') if x != \"[]\" else 0)\n",
    "df[\"others_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('others') if x != \"[]\" else 0)\n",
    "df[\"physical_exam_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('physical exam') if x != \"[]\" else 0)\n",
    "df[\"evaluatory_term_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('evaluatory term') if x != \"[]\" else 0)\n",
    "df[\"imaging_count\"] = df[\"meat_entities_type\"].apply(lambda x: x.count('imaging') if x != \"[]\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39757998.json     3421\n",
       "39784392.json     2958\n",
       "39403257.json     2723\n",
       "469388729.json    2622\n",
       "39756115.json     2572\n",
       "                  ... \n",
       "39747147.json        1\n",
       "39393698.json        1\n",
       "468783093.json       1\n",
       "49236879.json        1\n",
       "39747336.json        1\n",
       "Name: chart_id, Length: 19961, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.chart_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E119      15.040670\n",
       "000       11.013067\n",
       "Z684       8.395283\n",
       "J449       4.061162\n",
       "I10        3.567354\n",
       "            ...    \n",
       "C9101      0.000055\n",
       "I63012     0.000055\n",
       "M0608      0.000055\n",
       "C6310      0.000055\n",
       "D641       0.000055\n",
       "Name: code1, Length: 3383, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"code1\"].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.code1 == \"000\"].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep = 'first',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medicare Part C    1400150\n",
       "Commercial           28647\n",
       "commercial           16502\n",
       "medicare_part_c      10152\n",
       "TNM                   1667\n",
       "Name: DX Codetype, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DX Codetype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E119     250298\n",
       "Z684     123777\n",
       "J449      67896\n",
       "I10       61087\n",
       "I509      34586\n",
       "          ...  \n",
       "F1098         1\n",
       "M9050         1\n",
       "C9240         1\n",
       "C8416         1\n",
       "I519          1\n",
       "Name: code1, Length: 3382, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"code1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          4903\n",
       "[array([6809])]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             4066\n",
       "[array([6809]), array([6809])]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1660\n",
       "[array([1191])]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1410\n",
       "[array([25480])]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1363\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ... \n",
       "[array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([2418]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352]), array([20352])]                                                                                                                                1\n",
       "[array([51428]), array([51428]), array([253182]), array([593411]), array([6809]), array([1670007]), array([1670007]), array([51428])]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
       "[array([214199]), array([19831]), array([304962]), array([18631]), array([214199]), array([19831]), array([304962]), array([18631]), array([0]), array([214199]), array([19831]), array([304962]), array([18631])]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
       "[array([4603]), array([4603]), array([20352]), array([6058]), array([4603]), array([114202]), array([4603]), array([114202]), array([114202]), array([4603]), array([20352]), array([4603]), array([4603]), array([5470]), array([6058]), array([6058]), array([29046]), array([4603]), array([4603]), array([20352]), array([6058]), array([4603]), array([4603]), array([4603]), array([20352]), array([114202]), array([4603]), array([114202]), array([114202]), array([4603]), array([6058]), array([4603]), array([20352]), array([4603]), array([4603]), array([5470]), array([6058]), array([6058]), array([29046]), array([4603]), array([4603]), array([20352]), array([6058]), array([4603])]       1\n",
       "[array([8640]), array([8640]), array([8640]), array([8640]), array([435]), array([435]), array([8640]), array([8640])]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
       "Name: parent_rxcui_mapping, Length: 25206, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.parent_rxcui_mapping.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning parent_rxcui_mapping and chart_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parent_rxcui_mapping'] = df['parent_rxcui_mapping'].str.replace('array(())','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"parent_rxcui_mapping\"] = df[\"parent_rxcui_mapping\"].apply(lambda s: ast.literal_eval(s) if type(s) != float else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"parent_rxcui_mapping\"] = df[\"parent_rxcui_mapping\"].apply(lambda x:[j for i in x for j in i] if type(x) != float and x != None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     [6809]\n",
       "1                                                     [6809]\n",
       "2          [29046, 29046, 29046, 29046, 29046, 29046, 29046]\n",
       "3                                                     [6809]\n",
       "4                                                    [17767]\n",
       "                                 ...                        \n",
       "1805759                                                   []\n",
       "1805760                                                   []\n",
       "1805761                                                   []\n",
       "1805762                                                   []\n",
       "1805763                                                   []\n",
       "Name: parent_rxcui_mapping, Length: 1457118, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"parent_rxcui_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chart_id'] = df['chart_id'].str.replace('.json','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"16thFeb2022_100_120_merged_main_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"16thFeb2022_100_120_merged_main_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'code1', 'final_codes', 'query_source', 'DX Codetype',\n",
       "       'DX Category', 'DX Condition Type', 'DXCAT3', 'enc_id', 'meat', 'text',\n",
       "       'page', 'section', 'DX Context', 'NLP_VERSION', 'meat_entities',\n",
       "       'meat_entities_text', 'meat_entities_type', 'parent_rxcui_mapping',\n",
       "       'final_code_family', 'telehealth_encounter', 'dos_start', 'dos_end',\n",
       "       'enc_class', 'unique_codes', 'code_count', 'npi.type', 'chart_id',\n",
       "       'medicine_count', 'labtest_count',\n",
       "       'embedded radiology/lab results_count', 'devices_count',\n",
       "       'abnormal findings_count', 'generic term_count', 'plan_count',\n",
       "       'procedure_count', 'radiology_count', 'labs_count', 'rx_count',\n",
       "       'referral_count', 'symptoms_count', 'therapy_count', 'procedures_count',\n",
       "       'others_count', 'physical_exam_count', 'evaluatory_term_count',\n",
       "       'imaging_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns = ['Unnamed: 0','meat_entities', 'meat_entities_text','meat_entities_type'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates(keep = 'first',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salesforce's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = pd.read_csv(\"sf_w_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>chart_id</th>\n",
       "      <th>code</th>\n",
       "      <th>l1_finish_time</th>\n",
       "      <th>l1_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001210431</td>\n",
       "      <td>Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...</td>\n",
       "      <td>G40209</td>\n",
       "      <td>2021-12-14 08:19:30.000</td>\n",
       "      <td>Add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001210431</td>\n",
       "      <td>Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-14 08:19:30.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001210431</td>\n",
       "      <td>Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...</td>\n",
       "      <td>D580</td>\n",
       "      <td>2021-12-14 08:19:30.000</td>\n",
       "      <td>ASR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001210431</td>\n",
       "      <td>Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...</td>\n",
       "      <td>E039</td>\n",
       "      <td>2021-12-14 08:19:30.000</td>\n",
       "      <td>Add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001210431</td>\n",
       "      <td>Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...</td>\n",
       "      <td>E039</td>\n",
       "      <td>2021-12-14 08:19:30.000</td>\n",
       "      <td>ASR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id                                           chart_id    code  \\\n",
       "0  2001210431  Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...  G40209   \n",
       "1  2001210431  Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...     NaN   \n",
       "2  2001210431  Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...    D580   \n",
       "3  2001210431  Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...    E039   \n",
       "4  2001210431  Cambia_MRA_4RD9MD6ND13_100000000153_910433740_...    E039   \n",
       "\n",
       "            l1_finish_time l1_pc  \n",
       "0  2021-12-14 08:19:30.000   Add  \n",
       "1  2021-12-14 08:19:30.000   NaN  \n",
       "2  2021-12-14 08:19:30.000   ASR  \n",
       "3  2021-12-14 08:19:30.000   Add  \n",
       "4  2021-12-14 08:19:30.000   ASR  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17650238 entries, 0 to 17650237\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   project_id      object\n",
      " 1   chart_id        object\n",
      " 2   code            object\n",
      " 3   l1_finish_time  object\n",
      " 4   l1_pc           object\n",
      "dtypes: object(5)\n",
      "memory usage: 673.3+ MB\n"
     ]
    }
   ],
   "source": [
    "sf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf2 = sf.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"chart_id\"] = df2[\"chart_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"code1\"] = df2[\"code1\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf2[\"chart_id\"] = sf2[\"chart_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf2[\"code\"] = sf2[\"code\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code1</th>\n",
       "      <th>final_codes</th>\n",
       "      <th>query_source</th>\n",
       "      <th>DX Codetype</th>\n",
       "      <th>DX Category</th>\n",
       "      <th>DX Condition Type</th>\n",
       "      <th>DXCAT3</th>\n",
       "      <th>enc_id</th>\n",
       "      <th>meat</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>therapy_count</th>\n",
       "      <th>procedures_count</th>\n",
       "      <th>others_count</th>\n",
       "      <th>physical_exam_count</th>\n",
       "      <th>evaluatory_term_count</th>\n",
       "      <th>imaging_count</th>\n",
       "      <th>project_id</th>\n",
       "      <th>code</th>\n",
       "      <th>l1_finish_time</th>\n",
       "      <th>l1_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E119</td>\n",
       "      <td>['E119']</td>\n",
       "      <td>exact</td>\n",
       "      <td>Medicare Part C</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Chronic</td>\n",
       "      <td>E11</td>\n",
       "      <td>1</td>\n",
       "      <td>['3-526', '5-1460', '5-1479']</td>\n",
       "      <td>Diabetes mellitus type 2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E119</td>\n",
       "      <td>['E119']</td>\n",
       "      <td>exact</td>\n",
       "      <td>Medicare Part C</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Chronic</td>\n",
       "      <td>E11</td>\n",
       "      <td>1</td>\n",
       "      <td>['3-526', '5-1460', '5-1479']</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I219</td>\n",
       "      <td>['I219']</td>\n",
       "      <td>exact</td>\n",
       "      <td>Medicare Part C</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Acute</td>\n",
       "      <td>I21</td>\n",
       "      <td>1</td>\n",
       "      <td>['3-1949', '5-1171', '5-1202', '6-389', '6-799...</td>\n",
       "      <td>heart attack</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E119</td>\n",
       "      <td>['E119']</td>\n",
       "      <td>exact</td>\n",
       "      <td>Medicare Part C</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Chronic</td>\n",
       "      <td>E11</td>\n",
       "      <td>1</td>\n",
       "      <td>['3-526', '5-1460', '5-1479']</td>\n",
       "      <td>DMT2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I4891</td>\n",
       "      <td>['I4891']</td>\n",
       "      <td>exact</td>\n",
       "      <td>Medicare Part C</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Acute</td>\n",
       "      <td>I48</td>\n",
       "      <td>2</td>\n",
       "      <td>['8-155']</td>\n",
       "      <td>atrial fibrillation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2001211088</td>\n",
       "      <td>I4891</td>\n",
       "      <td>2021-10-25 10:09:28.000</td>\n",
       "      <td>Add</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   code1 final_codes query_source      DX Codetype  DX Category  \\\n",
       "0   E119    ['E119']        exact  Medicare Part C         19.0   \n",
       "1   E119    ['E119']        exact  Medicare Part C         19.0   \n",
       "2   I219    ['I219']        exact  Medicare Part C         86.0   \n",
       "3   E119    ['E119']        exact  Medicare Part C         19.0   \n",
       "4  I4891   ['I4891']        exact  Medicare Part C         96.0   \n",
       "\n",
       "  DX Condition Type DXCAT3  enc_id  \\\n",
       "0           Chronic    E11       1   \n",
       "1           Chronic    E11       1   \n",
       "2             Acute    I21       1   \n",
       "3           Chronic    E11       1   \n",
       "4             Acute    I48       2   \n",
       "\n",
       "                                                meat  \\\n",
       "0                      ['3-526', '5-1460', '5-1479']   \n",
       "1                      ['3-526', '5-1460', '5-1479']   \n",
       "2  ['3-1949', '5-1171', '5-1202', '6-389', '6-799...   \n",
       "3                      ['3-526', '5-1460', '5-1479']   \n",
       "4                                          ['8-155']   \n",
       "\n",
       "                       text  ...  therapy_count procedures_count others_count  \\\n",
       "0  Diabetes mellitus type 2  ...              0                0            0   \n",
       "1                  Diabetes  ...              0                0            0   \n",
       "2              heart attack  ...              0                0            0   \n",
       "3                      DMT2  ...              0                0            0   \n",
       "4       atrial fibrillation  ...              0                0            0   \n",
       "\n",
       "  physical_exam_count evaluatory_term_count imaging_count  project_id   code  \\\n",
       "0                   0                     0             0         NaN    NaN   \n",
       "1                   0                     0             0         NaN    NaN   \n",
       "2                   0                     0             0         NaN    NaN   \n",
       "3                   0                     0             0         NaN    NaN   \n",
       "4                   0                     0             0  2001211088  I4891   \n",
       "\n",
       "            l1_finish_time l1_pc  \n",
       "0                      NaN   NaN  \n",
       "1                      NaN   NaN  \n",
       "2                      NaN   NaN  \n",
       "3                      NaN   NaN  \n",
       "4  2021-10-25 10:09:28.000   Add  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = df2.merge(sf2, left_on=['chart_id','code1'], right_on = ['chart_id','code'], how='left')\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the output variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[\"output\"] = np.where(final[\"code1\"] == final[\"code\"],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code1', 'final_codes', 'query_source', 'DX Codetype', 'DX Category',\n",
       "       'DX Condition Type', 'DXCAT3', 'enc_id', 'meat', 'text', 'page',\n",
       "       'section', 'DX Context', 'NLP_VERSION', 'parent_rxcui_mapping',\n",
       "       'final_code_family', 'telehealth_encounter', 'dos_start', 'dos_end',\n",
       "       'enc_class', 'unique_codes', 'code_count', 'npi.type', 'chart_id',\n",
       "       'medicine_count', 'labtest_count',\n",
       "       'embedded radiology/lab results_count', 'devices_count',\n",
       "       'abnormal findings_count', 'generic term_count', 'plan_count',\n",
       "       'procedure_count', 'radiology_count', 'labs_count', 'rx_count',\n",
       "       'referral_count', 'symptoms_count', 'therapy_count', 'procedures_count',\n",
       "       'others_count', 'physical_exam_count', 'evaluatory_term_count',\n",
       "       'imaging_count', 'project_id', 'code', 'l1_finish_time', 'l1_pc',\n",
       "       'output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final.to_csv(\"16thFeb2022_100k_120k_data_merged_with_sf_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
